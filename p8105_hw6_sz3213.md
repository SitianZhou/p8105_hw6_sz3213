p8105_hw6_sz3213
================
Sitian Zhou
2023-11-18

## Problem 1

``` r
homicide_df <-
  read_csv("data/homicide-data.csv") |> 
  mutate(
    city_state = str_c(city, ", ", state),
    resolved = as.numeric(disposition == "Closed by arrest")
  ) |> 
  filter(city_state != "Tulsa, AL" & victim_race != "Unknown") |> 
  filter(victim_race =="Black" | victim_race == "White") |> 
  mutate(victim_age = as.numeric(victim_age)) |> 
  drop_na()
```

``` r
# fit glm
fit_logistic =
  homicide_df |> 
  filter(city_state == "Baltimore, MD") |> 
  glm(resolved ~ victim_age + victim_sex + victim_race, data = _, family = binomial())

fit_logistic |> 
  broom::tidy() |> 
  mutate(OR = exp(estimate),
         OR_CI_upper = exp(estimate + 1.96 * std.error),
         OR_CI_lower = exp(estimate - 1.96 * std.error)) |>
  filter(term == "victim_sexMale") |> 
  select(OR, OR_CI_lower, OR_CI_upper) |>
  knitr::kable(digits = 3)
```

|    OR | OR_CI_lower | OR_CI_upper |
|------:|------------:|------------:|
| 0.426 |       0.325 |       0.558 |

``` r
# loop over each city
results_df <-
  homicide_df |>
  nest(data = c(resolved, victim_sex), .by = city_state) |> 
  mutate(
    models = map(data, \(df) glm(resolved ~ victim_sex, data = df, family = binomial())),
    results = map(models, broom::tidy)
  ) |> 
  select(-models) |> 
  unnest(results) |> 
  mutate(OR = exp(estimate),
         OR_CI_upper = exp(estimate + 1.96 * std.error),
         OR_CI_lower = exp(estimate - 1.96 * std.error)) |> 
  filter(term == "victim_sexMale") |> 
  select(city_state, OR, OR_CI_lower, OR_CI_upper)

results_df |>
  slice(1:5) |> 
  knitr::kable(digits = 3)
```

| city_state      |    OR | OR_CI_lower | OR_CI_upper |
|:----------------|------:|------------:|------------:|
| Albuquerque, NM | 1.793 |       0.880 |       3.652 |
| Atlanta, GA     | 0.990 |       0.680 |       1.442 |
| Baltimore, MD   | 0.387 |       0.297 |       0.504 |
| Baton Rouge, LA | 0.360 |       0.199 |       0.651 |
| Birmingham, AL  | 0.891 |       0.589 |       1.346 |

``` r
#plots
results_df |> 
  mutate(city_state = fct_reorder(city_state, OR)) |> 
  ggplot(aes(x = city_state, y = OR)) + 
  geom_point() + 
  geom_errorbar(aes(ymin = OR_CI_lower, ymax = OR_CI_upper)) + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

![](p8105_hw6_sz3213_files/figure-gfm/plot%20for%20OR%20and%20CI%20for%20each%20city-1.png)<!-- -->

From the plot, most cities have odds ratios that are smaller than 1,
which suggests that crimes with male victims have smaller odds of
resolution compared to crimes with female victims after adjusting for
victim age and race. However, Albuquerque, NM has a much higher OR
compare to the rest of the cities, which implies that crimes with female
victims have smaller odds of resolution.

## Problem 2

``` r
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2022-01-01",
    date_max = "2022-12-31") |>
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) |>
  select(name, id, everything())
```

``` r
bootstrap_results <-
  weather_df |> 
  modelr::bootstrap(n = 5000) |> 
  mutate(
    models = map(strap, \(df) lm(tmax ~ tmin + prcp, data = df)),
    summary = map(models, broom::glance),
    results = map(models, broom::tidy)) |> 
  select(-models) |> 
  unnest(summary, results) |> 
  select(id = .id, r.squared, term, estimate) |> 
  pivot_wider(
    names_from = term,
    values_from = estimate) |> 
  mutate(
    log_b1b2 = log(tmin * prcp)
  ) |> 
  select(id, r.squared, log_b1b2)
```

``` r
bootstrap_results |> 
  ggplot(aes(x = r.squared)) + geom_density() + 
  labs(title = "Distribution of estimated r square")
```

![](p8105_hw6_sz3213_files/figure-gfm/CI%20for%20r2-1.png)<!-- -->

``` r
LB_r = bootstrap_results |> pull(r.squared) |>  quantile(0.025)
UB_r =bootstrap_results |> pull(r.squared) |>  quantile(0.975)

c(LB_r, UB_r)|> 
  knitr::kable(digits = 3)
```

|       |     x |
|:------|------:|
| 2.5%  | 0.888 |
| 97.5% | 0.940 |

The distribution of $\hat{r^2}$ is slightly left-skewed, with the range
from 0.86 to 0.96 and the mode around 0.92. The 2.5% and 97.5% quantiles
of the distribution are 0.888 and 0.94, respectively, and the
corresponding 95% confidence interval is (0.888, 0.94).

``` r
bootstrap_results |> 
  filter(log_b1b2 != "NaN") |> 
  ggplot(aes(x = log_b1b2)) + geom_density() +
  labs(title = "Distribution of estimated log(beta1 * beta2)")
```

![](p8105_hw6_sz3213_files/figure-gfm/CI%20for%20logb1b2-1.png)<!-- -->

``` r
LB_b = bootstrap_results |> filter(log_b1b2 != "NaN") |> pull(log_b1b2) |>  quantile(0.025)
UB_b =bootstrap_results |> filter(log_b1b2 != "NaN") |> pull(log_b1b2) |>  quantile(0.975)

c(LB_b, UB_b)|> 
  knitr::kable(digits = 3)
```

|       |      x |
|:------|-------:|
| 2.5%  | -8.930 |
| 97.5% | -4.567 |

The distribution of $log(\hat{\beta_1} * \hat{\beta_2})$ is heavily
left-skewed, with the range from -12 to -4 and the mode around -5.5. The
2.5% and 97.5% quantiles of the distribution are -8.93 and -4.567,
respectively, and the corresponding 95% confidence interval is (-8.93,
-4.567).

## Problem 3

``` r
bw_df <-
  read_csv("data/birthweight.csv", na = c("", "."))
```

data cleaning

``` r
bw_df_clean <-
  bw_df |> 
  mutate(
    babysex = as.factor(babysex),
    frace = as.factor(frace),
    malform = as.factor(malform),
    mrace = as.factor(mrace)
  ) |> 
  select(bwt, everything())
```

``` r
hypo_model = lm(bwt ~ bhead + blength + delwt + gaweeks + malform + smoken , data = bw_df_clean)
summary(hypo_model) |> broom::tidy()
```

    ## # A tibble: 7 × 5
    ##   term        estimate std.error statistic   p.value
    ##   <chr>          <dbl>     <dbl>     <dbl>     <dbl>
    ## 1 (Intercept) -6223.      95.5     -65.2   0        
    ## 2 bhead         135.       3.50     38.7   2.77e-281
    ## 3 blength        78.7      2.07     37.9   4.57e-272
    ## 4 delwt           2.09     0.200    10.5   2.37e- 25
    ## 5 gaweeks        14.6      1.49      9.77  2.68e- 22
    ## 6 malform1       37.3     73.1       0.511 6.10e-  1
    ## 7 smoken         -2.27     0.583    -3.90  9.77e-  5

``` r
# because malform has p-value > 0.05, we remove it from the model
my_model = lm(bwt ~ bhead + blength + delwt + gaweeks + smoken , data = bw_df_clean)
summary(my_model) |> broom::tidy()
```

    ## # A tibble: 6 × 5
    ##   term        estimate std.error statistic   p.value
    ##   <chr>          <dbl>     <dbl>     <dbl>     <dbl>
    ## 1 (Intercept) -6223.      95.5      -65.2  0        
    ## 2 bhead         135.       3.50      38.7  1.92e-281
    ## 3 blength        78.7      2.07      37.9  4.51e-272
    ## 4 delwt           2.09     0.200     10.5  2.20e- 25
    ## 5 gaweeks        14.6      1.49       9.76 2.74e- 22
    ## 6 smoken         -2.26     0.582     -3.89 1.04e-  4

I first hypothesized factors that are likely contributing to children’s
birth weights as the primary model. I included six predictors: `bhead`,
`blength`, `delwt`, `gaweeks`, `malform`, and `smoken`. Then I performed
the backword elimination to examine if all predictors are significant.
The coefficient of `malform` variable has the greatest p-value which is
0.61, and this value is greater than the threshold of $\alpha$ equals
0.05, so I excluded it from the model and refit the rest predictors. The
re-fitted model have five predictors and all coefficients have p-values
less than 0.05. Thus, I will keep all predictors and conclude that the
final model includes `bhead`, `blength`, `delwt`, `gaweeks`, and
`smoken`.

``` r
bw_df_clean |> 
  add_predictions(my_model) |> 
  add_residuals(my_model) |> 
  ggplot(aes(x = pred, y = resid)) +
  geom_point(alpha = 0.5) +
  geom_smooth() +
  labs(title = "Model residuals against fitted values")
```

![](p8105_hw6_sz3213_files/figure-gfm/residuals%20-%20fitted%20values-1.png)<!-- -->

``` r
# cv
model_1 = lm(bwt ~ blength + gaweeks, data = bw_df_clean)
model_2 = lm(bwt ~ bhead + blength + babysex + 
               bhead * blength + bhead * babysex + blength * babysex, data = bw_df_clean)
cv_df <-
  crossv_mc(bw_df_clean, 100) 

cv_df <-  
  cv_df |> 
  mutate(
    my_model  = map(train, \(df) lm(bwt ~ bhead + blength + delwt + gaweeks + smoken, 
                                    data = df)),
    model_1  = map(train, \(df) lm(bwt ~ blength + gaweeks, data = df)),
    model_2  = map(train, \(df) lm(bwt ~ bhead + blength + babysex + 
               bhead * blength + bhead * babysex + blength * babysex, data = df))) |> 
  mutate(
    rmse_my_model = map2_dbl(my_model, test, \(mod, df) rmse(model = mod, data = df)),
    rmse_model_1 = map2_dbl(model_1, test, \(mod, df) rmse(model = mod, data = df)),
    rmse_model_2 = map2_dbl(model_2, test, \(mod, df) rmse(model = mod, data = df)))
```

``` r
cv_df |> 
  select(starts_with("rmse")) |> 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") |> 
  mutate(model = fct_inorder(model)) |> 
  ggplot(aes(x = model, y = rmse, fill = model)) + geom_violin()
```

![](p8105_hw6_sz3213_files/figure-gfm/violin%20plot-1.png)<!-- -->

According to the violin plot, my_model has the lowest rmse, and model_2
has a slightly higher rmse than my_model. Model_1 has a much higher rmse
compared to the other models, which implies the predictions made using
this model could be less accurate than the other two.
